{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import argparse\n",
    "from pdf2image.exceptions import (\n",
    "    PDFInfoNotInstalledError,\n",
    "    PDFPageCountError,\n",
    "    PDFSyntaxError\n",
    ")\n",
    "import cv2\n",
    "import numpy as np\n",
    "import piexif\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.util import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import ne_chunk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finally\n"
     ]
    }
   ],
   "source": [
    "def reduce_lengthening(text):\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    return pattern.sub(r\"\\1\\1\", text);\n",
    "print(reduce_lengthening(\"finallllllly\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazziing\n",
      "[('total', 0.9722222222222222), ('iota', 0.027777777777777776)]\n"
     ]
    }
   ],
   "source": [
    "from pattern.en import suggest\n",
    "\n",
    "word = \"amazzziiing\"\n",
    "word_wlf = reduce_lengthening(word) #calling function defined above\n",
    "print( word_wlf) #word lengthening isn't being able to fix it completely\n",
    "\n",
    "correct_word = \"\"\n",
    "try:\n",
    "    correct_word = suggest(\"tota\") \n",
    "except:\n",
    "    correct_word = suggest(\"tota\")\n",
    "print(correct_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FileName', 'Total Amount'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"test.csv\")\n",
    "mean=df['Total Amount'].mean(skipna = True) \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(image, center = None, scale = 1.0):\n",
    "    angle=360\n",
    "    try:\n",
    "        angle=360-int(re.search('(?<=Rotate: )\\d+', pytesseract.image_to_osd(image)).group(0))\n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "    print(angle)\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValue(text,text1,text2,key):\n",
    "    predict1=0.0\n",
    "    predict2=0.0\n",
    "    predict3=0.0\n",
    "    predict=0.0\n",
    "    tot=False\n",
    "    if key in text and is_number(text[key])  :\n",
    "        predict1=getFloat(text[key])\n",
    "        return predict1\n",
    "    if key in text1 and is_number(text1[key])  :\n",
    "        predict2=getFloat(text1[key])\n",
    "    if key in text2 and is_number(text2[key])  :\n",
    "        predict3=getFloat(text2[key])\n",
    "    if predict1>0 or predict2>0 or predict3>0:\n",
    "        predict=max(predict1 , predict2 , predict3)\n",
    "    \n",
    "#     if key in text  and is_number(text[key]) :\n",
    "#         if(tot):\n",
    "#             if(predict<getFloat(text[key])):\n",
    "#                 predict=(predict+getFloat(text[key]))/2\n",
    "#         else:\n",
    "#             predict=getFloat(text[key])\n",
    "#             tot=True\n",
    "#     if key in text2  and is_number(text2[key]) and not tot:\n",
    "#         if(tot):\n",
    "#             if(predict<getFloat(text2[key])):\n",
    "#                 predict=(predict+getFloat(text2[key]))/2\n",
    "#         else:\n",
    "#             predict=getFloat(text2[key])\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    c=0;\n",
    "    for i in range(len(s)):\n",
    "        if s[i]==',':\n",
    "            c+=1\n",
    "    if c==1:\n",
    "        s=s.replace(',','.')\n",
    "    try:\n",
    "        return float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "def getFloat(s):\n",
    "    return float(s.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeTokens(tokens):\n",
    "    tok=[]\n",
    "    skip=0\n",
    "    for i in range(len(tokens)-2):\n",
    "        if skip>0:\n",
    "            skip=skip-1\n",
    "            continue\n",
    "        if is_number(tokens[i])and tokens[i].isnumeric() and is_number(tokens[i+2])and tokens[i+2].isnumeric() and (tokens[i+1]=='.' or int(tokens[i+2])<100):\n",
    "            tok.append(tokens[i]+tokens[i+1]+tokens[i+2])\n",
    "            skip=2\n",
    "        elif tokens[i].lower()=='sub':\n",
    "            if(not checkAlphaNum(tokens[i+1])):\n",
    "                if tokens[i+2].lower()=='total':\n",
    "                    tok.append(tokens[i]+tokens[i+2])\n",
    "                    skip=2\n",
    "            elif tokens[i+1].lower()=='total':\n",
    "                tok.append(tokens[i]+tokens[i+1])\n",
    "                skip=1\n",
    "            else:\n",
    "                tok.append(tokens[i])\n",
    "        else:\n",
    "            tok.append(tokens[i])\n",
    "    if((len(tokens)-2)>0):\n",
    "        tok.append(tokens[len(tokens)-2])\n",
    "        tok.append(tokens[len(tokens)-1])\n",
    "    elif((len(tokens)-1)>0):\n",
    "        tok.append(tokens[len(tokens)-1])\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkAlphaNum(word):\n",
    "    for i in range(0, len(word)):\n",
    "        if word[i].isalnum():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTax(ext):\n",
    "    ext1=[]\n",
    "    t=False\n",
    "    ap=False\n",
    "    last=0\n",
    "    s=0.0\n",
    "    for i in range(len(ext)):\n",
    "        w=ext[i]\n",
    "        if(w.lower()==\"tax\"):\n",
    "            t=True\n",
    "        elif(is_number(w) and t==True and getFloat(w)==(last+1)):\n",
    "            last+=1\n",
    "            ap=True\n",
    "        elif(is_number(w) and ap==True):\n",
    "            s+=getFloat(w)\n",
    "            ap=False\n",
    "        else:\n",
    "            t=False\n",
    "            ap=False\n",
    "        ext1.append(w)\n",
    "    if(s>0):\n",
    "        ext1.append('tax')\n",
    "        ext1.append(str(s))\n",
    "    return ext1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(num,s):\n",
    "    if(num>1000 and s==\"sub\"):\n",
    "        return 0.0\n",
    "    if(num>70000):\n",
    "        return 0.0\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TE_197 58.3 58.3 0.0 10.0 0.0 0.0 58.3 0.0 22.0 358.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:264: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "keys=['due','total','credit','payment','tip','tl','subtotal','tax','amount','pay']\n",
    "for ind in df.index: \n",
    "    if ind<66:\n",
    "        continue\n",
    "    nm=df['FileName'][ind]#'TE_133' #\n",
    "    ta=df['Total Amount'][ind]\n",
    "    predict=mean\n",
    "    pdf=\".\\\\Dataset\\\\Test\\\\\"+nm+\".pdf\"\n",
    "    pages = convert_from_path(pdf,poppler_path = r\"C:\\Program Files\\poppler-0.51\\bin\")\n",
    "    for page in pages:\n",
    "        page.save('out.jpg', 'JPEG')\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "    image = cv2.imread(\"out.jpg\" )\n",
    "    #     image= rotate(image)\n",
    "    height, width = image.shape[:2]\n",
    "    #     for y in range(image.shape[0]):\n",
    "    #         image[y] = np.clip(0.5*np.array(image[y]), 0, 255)\n",
    "    # image=cv2.resize(image, (int(width-(width/30)), int(height-(height/30))), interpolation=cv2.INTER_LINEAR)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,21,11)\n",
    "    gray1=gray\n",
    "    gray = cv2.medianBlur(gray,3)\n",
    "#     gray = cv2.medianBlur(gray,3)\n",
    "#     gray = cv2.threshold(gray,50,255,cv2.THRESH_BINARY)[1]\n",
    "#     gray = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    # gray = cv2.dilate(gray, np.ones((5,5), np.uint8) , iterations=1)\n",
    "\n",
    "\n",
    "\n",
    "    kernel = np.array([[-2, 0, -2], \n",
    "                       [0, 9,0], \n",
    "                       [-2, 0, -2]])\n",
    "    # Sharpen image\n",
    "    # gray1 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # gray1 = cv2.filter2D(gray1, -1, kernel)\n",
    "    # gray1 = cv2.adaptiveThreshold(gray1,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,21,11)\n",
    "    # gray1 = cv2.medianBlur(gray1,3)\n",
    "    # # # gray = cv2.erode(gray, kernel , iterations=1)\n",
    "    # gray = cv2.dilate(gray, np.ones((5,5), np.uint8) , iterations=1)\n",
    "    # gray1 = cv2.dilate(gray1, np.ones((5,5), np.uint8) , iterations=1)\n",
    "    # orig = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # orig = cv2.dilate(orig, np.ones((5,5), np.uint8) , iterations=1)\n",
    "    # #gray= cv2.fastNlMeansDenoisingColored(gray,None,10,10,7,21)\n",
    "    # #gray = cv2.threshold(gray,100,255,cv2.THRESH_BINARY)[1]\n",
    "\n",
    "\n",
    "#     gray1 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     gray1 = cv2.adaptiveThreshold(gray1,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,21,11)\n",
    "    gray1 = cv2.medianBlur(gray1,5)\n",
    "    # gray1 = cv2.dilate(gray1, np.ones((5,5), np.uint8) , iterations=1)\n",
    "\n",
    "\n",
    "    orig = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    orig = cv2.medianBlur(orig,3)\n",
    "    orig = cv2.dilate(orig, np.ones((5,5), np.uint8) , iterations=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    filename = \"xyz.png\".format(os.getpid())\n",
    "    cv2.imwrite(filename, gray)\n",
    "    filename1 = \"xyz1.png\".format(os.getpid())\n",
    "    cv2.imwrite(filename1, gray1)\n",
    "    filename2 = \"xyz2.png\".format(os.getpid())\n",
    "    cv2.imwrite(filename2, orig)\n",
    "    text = pytesseract.image_to_string(Image.open(filename), lang='eng',config=\"--psm 6\")\n",
    "    text1 = pytesseract.image_to_string(Image.open(filename1), lang='eng',config=\"--psm 6\")\n",
    "    text2=pytesseract.image_to_string(Image.open(filename2), lang='eng',config=\"--psm 6\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tokens1=mergeTokens(word_tokenize(text1))\n",
    "    tokens=mergeTokens(word_tokenize(text))\n",
    "    tokens2=mergeTokens(word_tokenize(text2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tokens1=list(filter(lambda x: not x.lower() in stopwords.words('english') and  checkAlphaNum(x) , tokens1))\n",
    "    tags1=nltk.pos_tag(tokens1)\n",
    "    tokens=list(filter(lambda x: not x.lower() in stopwords.words('english') and  checkAlphaNum(x) , tokens))\n",
    "    tags=nltk.pos_tag(tokens)\n",
    "    tokens2=list(filter(lambda x: not x.lower() in stopwords.words('english') and  checkAlphaNum(x) , tokens2))\n",
    "    tags2=nltk.pos_tag(tokens2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ext1=[]\n",
    "    ext=[]\n",
    "    ext2=[]\n",
    "    for x,y in tags1:\n",
    "        if y in ['NNP','NN','CD'] or x.lower() in keys:\n",
    "            ext1.append(x)\n",
    "    for x,y in tags:\n",
    "        if y in ['NNP','NN','CD'] or x.lower() in keys:\n",
    "            ext.append(x)\n",
    "    for x,y in tags2:\n",
    "        if y in ['NNP','NN','CD'] or x.lower() in keys:\n",
    "            ext2.append(x)\n",
    "    ext1=getTax(ext1)\n",
    "    ext=getTax(ext)\n",
    "    ext2=getTax(ext2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    bigram1=list(bigrams(ext1))\n",
    "    extBi1={}\n",
    "    for x,y in bigram1:\n",
    "        if (x.lower() not in keys and not is_number(x)):\n",
    "            suggestions=suggest(reduce_lengthening(x.lower()))\n",
    "            suggested=False\n",
    "            if x.lower()==\"ove\":\n",
    "                x=\"due\"\n",
    "                suggested=True\n",
    "            if x.lower()==\"u\":\n",
    "                x=\"total\"\n",
    "                suggested=True\n",
    "            for a,b in suggestions:\n",
    "                if suggested:\n",
    "                    break\n",
    "                if a in keys:\n",
    "                    x=a\n",
    "                    suggested=True\n",
    "                    break;\n",
    "            if not suggested:\n",
    "                x,z=suggest(reduce_lengthening(x.lower()))[0]\n",
    "        if x.lower() not in extBi1 or (not is_number(extBi1[x.lower()])) or (is_number(y) and getFloat(y)>getFloat(extBi1[x.lower()])):\n",
    "            extBi1[x.lower()]=y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    bigram=list(bigrams(ext))\n",
    "    extBi={}\n",
    "    for x,y in bigram:\n",
    "        if (x.lower() not in keys and not is_number(x)):\n",
    "            suggestions=suggest(reduce_lengthening(x.lower()))\n",
    "            suggested=False\n",
    "            if x.lower()==\"ove\":\n",
    "                x=\"due\"\n",
    "                suggested=True\n",
    "            if x.lower()==\"u\":\n",
    "                x=\"total\"\n",
    "                suggested=True\n",
    "            for a,b in suggestions:\n",
    "                if suggested:\n",
    "                    break\n",
    "                if a in keys:\n",
    "                    x=a\n",
    "                    suggested=True\n",
    "                    break;\n",
    "            if not suggested:\n",
    "                x,z=suggest(reduce_lengthening(x.lower()))[0]\n",
    "        if x.lower() not in extBi or (not is_number(extBi[x.lower()])) or (is_number(y) and getFloat(y)>getFloat(extBi[x.lower()])):\n",
    "            extBi[x.lower()]=y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    bigram2=list(bigrams(ext2))\n",
    "    extBi2={}\n",
    "    for x,y in bigram2:\n",
    "        if (x.lower() not in keys and not is_number(x)):\n",
    "            suggestions=suggest(reduce_lengthening(x.lower()))\n",
    "            suggested=False\n",
    "            if x.lower()==\"ove\":\n",
    "                x=\"due\"\n",
    "                suggested=True\n",
    "            if x.lower()==\"u\":\n",
    "                x=\"total\"\n",
    "                suggested=True\n",
    "            for a,b in suggestions:\n",
    "                if suggested:\n",
    "                    break\n",
    "                if a in keys:\n",
    "                    x=a\n",
    "                    suggested=True\n",
    "                    break;\n",
    "            if not suggested:\n",
    "                x,z=suggest(reduce_lengthening(x.lower()))[0]\n",
    "        if x.lower() not in extBi2 or (not is_number(extBi2[x.lower()])) or (is_number(y) and getFloat(y)>getFloat(extBi2[x.lower()])):\n",
    "            extBi2[x.lower()]=y\n",
    "\n",
    "\n",
    "\n",
    "    tot=False\n",
    "    amt=check(getValue(extBi,extBi1,extBi2,'amount'),\"no\")\n",
    "    due=check(getValue(extBi,extBi1,extBi2,'due'),\"no\")\n",
    "    t=check(getValue(extBi,extBi1,extBi2,'total'),\"no\")\n",
    "    if(t==0):\n",
    "        t=check(getValue(extBi,extBi1,extBi2,'totale'),\"no\")\n",
    "    credit=check(getValue(extBi,extBi1,extBi2,'credit'),\"no\")\n",
    "    pay=check(getValue(extBi,extBi1,extBi2,'payment'),\"no\")\n",
    "    tip=check(getValue(extBi,extBi1,extBi2,'tip'),\"no\")\n",
    "    tl=check(getValue(extBi,extBi1,extBi2,'tl'),\"no\")\n",
    "    pay=check(getValue(extBi,extBi1,extBi2,'pay'),\"no\")\n",
    "    subtotal=check(getValue(extBi,extBi1,extBi2,'subtotal'),\"no\")\n",
    "    tax=check(getValue(extBi,extBi1,extBi2,'tax'),\"no\")\n",
    "    if tax==0:\n",
    "        tax=subtotal/20\n",
    "    subT=check(subtotal+tax,\"sub\")\n",
    "    subset=False\n",
    "    if due>0 or t>0 or credit>0 or pay>0 or tip>0 or tl>0 or amt>0 or pay>0:\n",
    "        predict=max(due,t,credit,pay,tip,tl,amt,pay)\n",
    "        if (t>1 and amt>1 and amt<t):\n",
    "            predict=amt\n",
    "        elif predict>0 and (not (subtotal==0 or tax==0)) and ((subT<(predict-(predict/2))) or (subT>predict and (subT<(predict+(predict/100)))) ) and subT>0 and not (predict>330 and predict<340):\n",
    "            predict=subT\n",
    "        elif t>1:\n",
    "            predict=t\n",
    "        elif due>0:\n",
    "            predict=due\n",
    "        elif pay>0:\n",
    "            predict=pay\n",
    "        if((tip<predict and (predict!=subT  ) and tip>0 and not (predict>330 and predict<340))) or (str(subT).count(str(tip)))>0:\n",
    "            predict=tip\n",
    "            if((str(subT).count(str(tip)))>0):\n",
    "                subset=True\n",
    "        if(((due>subT and predict!=subT) or due<t) and due>1):\n",
    "            predict=due\n",
    "        if((str(subT).count(str(predict)))>0 and not subset) or (predict<10 and subT>predict and subT >50 and subT<90):\n",
    "            predict=subT\n",
    "        if(subT>predict and str(predict)[0]=='1' and subT >60 and subT <80):\n",
    "            predict+=60\n",
    "        count+=1\n",
    "    else:\n",
    "        if subtotal==0:\n",
    "            for i in ext:\n",
    "                if(is_number(i) and getFloat(i)<30):\n",
    "                    subtotal+=getFloat(i)\n",
    "            for i in ext1:\n",
    "                if(is_number(i) and getFloat(i)<30):\n",
    "                    subtotal+=getFloat(i)\n",
    "            for i in ext2:\n",
    "                if(is_number(i) and getFloat(i)<30):\n",
    "                    subtotal+=getFloat(i)\n",
    "            subtotal=subtotal/3\n",
    "        if subtotal==0 and tax==0:\n",
    "            predict=mean\n",
    "            print(nm)\n",
    "        else:\n",
    "            predict=subtotal+tax\n",
    "            count+=1\n",
    "    df.set_value(ind,'Total Amount',round(predict, 2))\n",
    "    print(nm,ta,predict,due,t,credit,pay,tip,tl,amt,subT)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r\"test1.csv\", \"w\")\n",
    "f.write(df.to_csv(index=False, line_terminator='\\n'))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
